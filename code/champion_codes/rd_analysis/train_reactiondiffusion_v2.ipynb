{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;31mRuntimeError\u001B[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;31mImportError\u001B[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mSystemError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;31mSystemError\u001B[0m: <built-in method __contains__ of dict object at 0x7fbfaf870500> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/b7/gw6vgqcj6z982lrqvc6c2gd00000gn/T/ipykernel_31573/3578068613.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mexample_reactiondiffusion\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mget_rd_data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msindy_utils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mlibrary_size\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtraining_v2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtrain_network\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Research/convection_patterns/code/champion_codes/training_v2.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpickle\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#from autoencoder import full_network, define_loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mautoencoder_v2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfull_network\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdefine_loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/untitled/lib/python3.8/site-packages/tensorflow/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtyping\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_typing\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 37\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtools\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmodule_util\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_module_util\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     38\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlazy_loader\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLazyLoader\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_LazyLoader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/untitled/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpywrap_tensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_pywrap_tensorflow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 37\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meager\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     38\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;31m# pylint: enable=wildcard-import\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/untitled/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpywrap_tfe\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtf2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpywrap_tf_session\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meager\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mexecutor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meager\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmonitoring\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/untitled/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpywrap_tensorflow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pywrap_tf_session\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pywrap_tf_session\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_TF_SetTarget\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pywrap_tf_session\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_TF_SetConfig\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_reactiondiffusion import get_rd_data\n",
    "from sindy_utils import library_size\n",
    "from training_v2 import train_network\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": "training_data, validation_data, test_data = get_rd_data()",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": "params = {}\n\nparams['input_dim'] = training_data['y1'].size*training_data['y2'].size\nparams['latent_dim'] = 2\nparams['model_order'] = 1\nparams['poly_order'] = 3\nparams['include_sine'] = True\nparams['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n\n# sequential thresholding parameters\nparams['sequential_thresholding'] = True\nparams['coefficient_threshold'] = 0.1\nparams['threshold_frequency'] = 500\nparams['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\nparams['coefficient_initialization'] = 'constant'\n\n# loss function weighting\nparams['loss_weight_decoder'] = 1.0\nparams['loss_weight_sindy_z'] = 0.01\nparams['loss_weight_sindy_x'] = 0.5\nparams['loss_weight_sindy_regularization'] = 0.1\n\nparams['activation'] = 'sigmoid'\nparams['widths'] = [256]\n\n# training parameters\nparams['epoch_size'] = training_data['t'].size\nparams['batch_size'] = 1000\nparams['learning_rate'] = 1e-3\n\nparams['data_path'] = os.getcwd() + '/'\nparams['print_progress'] = True\nparams['print_frequency'] = 100\n\n# training time cutoffs\nparams['max_epochs'] = 3001\nparams['refinement_epochs'] = 1001",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "TRAINING\n",
      "Epoch 0\n",
      "   training loss 7.118495941162109, (0.16129039, 678.1984, 0.15067537, 0.9988337)\n",
      "   validation loss 7.529788017272949, (0.16121513, 719.27234, 0.15193182, 0.9988337)\n",
      "decoder loss ratio: 1.018597, decoder SINDy loss  ratio: 1.164120\n",
      "Epoch 100\n",
      "   training loss 0.24350601434707642, (0.09269848, 1.2762685, 0.08362685, 0.96231437)\n",
      "   validation loss 0.2458089292049408, (0.09598545, 1.294826, 0.081287555, 0.96231437)\n",
      "decoder loss ratio: 0.606460, decoder SINDy loss  ratio: 0.622835\n",
      "Epoch 200\n",
      "   training loss 0.20497074723243713, (0.07087415, 0.6482141, 0.06847048, 0.9337923)\n",
      "   validation loss 0.20698657631874084, (0.074388266, 0.67420655, 0.06495403, 0.9337923)\n",
      "decoder loss ratio: 0.470003, decoder SINDy loss  ratio: 0.497685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 21:32:54.510263: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-10 21:32:54.540716: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": "num_experiments = 10\ndf = pd.DataFrame()\nfor i in range(num_experiments):\n    print('EXPERIMENT %d' % i)\n\n    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n\n    params['save_name'] = 'rd_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n\n    tf.compat.v1.reset_default_graph()\n\n    results_dict = train_network(training_data, validation_data, params)\n    df = df.append({**results_dict, **params}, ignore_index=True)\n\ndf.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}