{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('/Users/edwardmcdugald/Research/convection_patterns_wip/code/ml_experiments')\n",
    "from myPDEFIND import *\n",
    "#sys.path.append('/Users/edwardmcdugald/Research/convection_patterns_wip/code/numerics')\n",
    "#import convection_patterns_v2 as cp\n",
    "\n",
    "#cp.solveSH(20*np.pi,20*np.pi,256,256,.1,100,\"SHAutoEncode_3\",Rscale=.5,\n",
    "#            beta=.45,amplitude=.1,init_flag=1,energy=False)\n",
    "data = sio.loadmat(\"/Users/edwardmcdugald/Research/convection_patterns_wip/code/data/SHAutoEncode_3.mat\")\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(3,3))\n",
    "ax.imshow(data['uu'][500,:,:])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tt = data['tt'][0][1:] #TVALUES, EXCLUDING FIRST ONE\n",
    "xx = data['xx']\n",
    "yy = data['yy']\n",
    "U = data['uu'][1:1001,:,:] #TAKE LAST 1000 U surfaces\n",
    "dt = data['tt'][0][1]-data['tt'][0][0]\n",
    "Ut = BackwardDiff(U,data['uu'][0:1000,:,:],dt) #Compute U derivatives\n",
    "n_samples = len(tt)\n",
    "N = len(xx)*len(yy)\n",
    "perm = np.random.permutation(int(.9*n_samples))\n",
    "training_samples = perm[:int(.8*n_samples)]\n",
    "val_samples = perm[int(.8*n_samples):]\n",
    "test_samples = np.arange(int(.9*n_samples), n_samples)\n",
    "\n",
    "#subsampling by factor of 2\n",
    "training_data = {'tt': tt[training_samples],\n",
    "                     'xx': xx[::2].T,\n",
    "                     'yy': yy[::2].T,\n",
    "                     'U': U[training_samples,::2,::2],\n",
    "                     'Ut': Ut[training_samples,::2,::2]}\n",
    "val_data = {'tt': tt[val_samples],\n",
    "                'xx': xx[::2].T,\n",
    "                'yy': yy[::2].T,\n",
    "                'U': U[val_samples,::2,::2],\n",
    "                'Ut': Ut[val_samples,::2,::2]}\n",
    "test_data = {'tt': tt[test_samples],\n",
    "                 'xx': xx[::2].T,\n",
    "                 'yy': yy[::2].T,\n",
    "                 'U': U[test_samples,::2,::2],\n",
    "                 'Ut': Ut[test_samples,::2,::2]}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u_train = training_data['U']\n",
    "u_test = test_data['U']\n",
    "u_val = val_data['U']\n",
    "u_train = u_train.astype('float32')\n",
    "u_test = u_test.astype('float32')\n",
    "u_val = u_val.astype('float32')\n",
    "print(u_train.shape)\n",
    "print(u_test.shape)\n",
    "print(u_val.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_dim = 1024\n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(256, activation='linear'),\n",
    "      layers.Dense(512, activation='sigmoid'),\n",
    "      layers.Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(2048, activation='linear'),\n",
    "      layers.Dense(4096, activation='sigmoid'),\n",
    "      layers.Dense(8192, activation='relu'),\n",
    "      layers.Dense(16384, activation='linear'),\n",
    "      layers.Reshape((128, 128))\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = Autoencoder(latent_dim)\n",
    "autoencoder.encoder.summary()\n",
    "autoencoder.decoder.summary()\n",
    "autoencoder.summary()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def my_loss_fn(x_in, x_out, dt):\n",
    "    squared_difference = tf.square(x_in - x_out)\n",
    "    ae_err = tf.reduce_mean(squared_difference, axis=-1)\n",
    "    z = autoencoder.encoder(x_in).numpy().reshape(32,32)\n",
    "    z_derivs = BackwardDiff(z[1:len(z)],z[0:len(z)-1],dt)\n",
    "\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "autoencoder.compile(optimizer='adam', loss=my_loss_fn)\n",
    "autoencoder.fit(u_train, u_train,\n",
    "                epochs=10,\n",
    "                batch_size=5,\n",
    "                shuffle=True,\n",
    "                validation_data=(u_test, u_test))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoded_data = autoencoder.encoder(u_val).numpy()\n",
    "decoded_data = autoencoder.decoder(encoded_data).numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(n):\n",
    "  idx = np.random.randint(1,99)\n",
    "  # display original\n",
    "  ax = plt.subplot(3, n, i + 1)\n",
    "  plt.imshow(u_val[idx])\n",
    "  plt.title(\"original\"+\"_\"+str(idx))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reshaped encoded\n",
    "  ax = plt.subplot(3, n, i + 1 + n)\n",
    "  plt.imshow(encoded_data[idx].reshape(32,32))\n",
    "  plt.title(\"encoded\"+\"_\"+str(idx))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reconstruction\n",
    "  ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "  plt.imshow(decoded_data[idx])\n",
    "  plt.title(\"reconstructed\"+\"_\"+str(idx))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "t = data['tt'].T[:,0]\n",
    "x = data['xx'].T[0,:]\n",
    "y = data['yy'].T[0,:]\n",
    "U = data['uu']\n",
    "print(\"data shape: \",np.shape(U))\n",
    "\n",
    "nx = len(x)\n",
    "ny = len(y)\n",
    "dx = x[1]-x[0]\n",
    "dy = y[1]-y[0]\n",
    "dt = t[1]-t[0]\n",
    "print(\"dt=\",dt,\"dx=\",dx,\"dy=\",dy)\n",
    "\n",
    "num_t = 20\n",
    "x_subsample = 8\n",
    "y_subsample = 8\n",
    "t_vals = np.arange(1,len(t),math.floor(len(t)/num_t))\n",
    "x_vals = np.arange(0,nx,x_subsample)\n",
    "y_vals = np.arange(0,ny,y_subsample)\n",
    "\n",
    "num_points = num_t*len(x_vals)*len(y_vals)\n",
    "print(\"feature vec length: \",num_points)\n",
    "print(dt)\n",
    "\n",
    "u = np.zeros((num_points,1))\n",
    "u_t = np.zeros((num_points,1))\n",
    "u_x = np.zeros((num_points,1))\n",
    "u_y = np.zeros((num_points,1))\n",
    "u_xx = np.zeros((num_points,1))\n",
    "u_yy = np.zeros((num_points,1))\n",
    "u_xy = np.zeros((num_points,1))\n",
    "lapu = np.zeros((num_points,1))\n",
    "biharmu = np.zeros((num_points,1))\n",
    "\n",
    "\n",
    "# setting parameters for spectral derivatives\n",
    "Lx = 2*x[len(x)-1] # Size of enclosing periodic rectangle\n",
    "Ly = 2*y[len(y)-1]\n",
    "\n",
    "i=0\n",
    "for t_idx in t_vals:\n",
    "    print(t_idx)\n",
    "    uu = U[t_idx,:,:]\n",
    "    uu_t = BackwardDiff(U[t_idx,:,:],U[t_idx-1,:,:],dt)\n",
    "    uu_x = SpectralDerivs(U[t_idx,:,:],Lx,Ly,'x')\n",
    "    uu_y = SpectralDerivs(U[t_idx,:,:],Lx,Ly,'y')\n",
    "    uu_xx = SpectralDerivs(U[t_idx,:,:],Lx,Ly,'xx')\n",
    "    uu_yy = SpectralDerivs(U[t_idx,:,:],Lx,Ly,'yy')\n",
    "    uu_xy = SpectralDerivs(U[t_idx,:,:],Lx,Ly,'xy')\n",
    "    lapuu = SpectralDerivs(U[t_idx,:,:],Lx,Ly,'laplacian')\n",
    "    biharmuu = SpectralDerivs(U[t_idx,:,:],Lx,Ly,'biharmonic')\n",
    "    for x_idx in x_vals:\n",
    "        for y_idx in y_vals:\n",
    "            u[i] = uu[x_idx,y_idx]\n",
    "            u_t[i] = uu_t[x_idx,y_idx]\n",
    "            u_x[i] = uu_x[x_idx,y_idx]\n",
    "            u_y[i] = uu_y[x_idx,y_idx]\n",
    "            u_xy[i] = uu_xy[x_idx,y_idx]\n",
    "            lapu[i] = lapuu[x_idx,y_idx]\n",
    "            biharmu[i] = biharmuu[x_idx,y_idx]\n",
    "            i+=1\n",
    "\n",
    "X = np.hstack([np.ones((num_points,1)), u, u**2, u**3,u**4,\n",
    "                   u_x, u_y, u_x**2, u_y**2, u_x*u_y,u_xy,\n",
    "               lapu, biharmu])\n",
    "description = ['','u','u^2','u^3','u^4',\n",
    "               'u_{x}','u_{y}','u_{x}^2','u_{y}^2','u_{x}u_{y}','u_{xy}'\n",
    "    ,'lapu','biharmu']\n",
    "\n",
    "c = TrainSTRidge(X,u_t,10**-5,1)\n",
    "print_pde(c, description)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
