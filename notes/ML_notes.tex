\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[hmargin=1in,vmargin=1in]{geometry}
\usepackage[shortlabels]{enumitem}
\usepackage{multicol}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[section]{placeins}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{listings}
\usepackage{amsmath,tkz-euclide}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, decorations.markings}
\usetkzobj{all}
\newtheorem{theorem}{Theorem}
\newtheorem*{theorem*}{Theorem}
%\usepackage{float}
%\floatplacement{figure}{H}
\newcounter{problem}
\newcounter{solution}
\graphicspath{{/Users/edwardmcdugald/Research/convection_patterns/figs/}}
\usepackage{chngcntr}
\counterwithin*{section}{part}

\parindent 0in
\parskip 1em
\Urlmuskip=0mu plus 1mu

\title{Machine Learning Experiment}
\author{Edward McDugald}


\begin{document}
\maketitle
\section{Introduction}
Convection rolls are known for their pattern forming properties. 
Experimental results demonstrate a range of patterns, which appear to be well-modeled by the Swift-Hohenberg PDE.
\[
    w_t = -(1+\nabla^2)^2w + Rw - w^3.
\] 
Work by Cross and Newell has sought to find generic models for pattern forming systems meeting certain conditions.
The most prevalent model in the literature appears to be essentially the minimizers of the regularized Cross-Newell energy functional
\[
    \varepsilon^{(\mu)}(\Theta) = \mu \int_{\Omega}(\nabla_{\vec{X}}\Theta)^2d\vec{X}+\frac{1}{\mu}\int_{\Omega}\left(1-\lvert \nabla_{\vec{X}}\Theta\rvert^2\right)^2d\vec{X}.
\]
The Cross-Newell framework does not capture all possible patterns and pattern defects seen in experiments, nor seen in SH simulations. The problem at hand is to find a Cross-Newell like equation that predicts a wider class of patterns than the current Cross-Newell equations.\newline
The current document outlines machine learning models to a range of related problems. Typically, machine learning experiments on PDE data either seek reduced order models as output, or seek to generate more efficient simulation algorithms. The range of machine learning experiments that will be explored here is not yet determined. Some of the main papers of interest here are the following: \newline
 \href{https://www.pnas.org/doi/pdf/10.1073/pnas.1517384113}{OG Kutz paper on SINDy- applicable to Dynamical Systems}.\newline
 \href{https://www.science.org/doi/pdf/10.1126/sciadv.1602614}{Kutz paper on PDE-FIND}\newline
 \href{https://github.com/snagcliffs/PDE-FIND}{Git for PDE-FIND}\newline
 \href{https://github.com/dynamicslab/pysindy}{PySINDy}\newline
    \href{https://www.pnas.org/doi/pdf/10.1073/pnas.1906995116}{Describes SINDy like approach for PDE data}\newline
    \href{https://reader.elsevier.com/reader/sd/pii/S0045782522004807?token=828D185F06DE28418D9E46B544E846EEDC227470A1436A8191877A3EC18DC832E4B81EE95D31BCC28E5B0B0B7D00373C&originRegion=us-east-1&originCreation=20220928051957}{Published paper on LaSDI- Bill's work}\newline
    \href{https://arxiv.org/pdf/2204.12005.pdf}{gLaSDI preprint - Bill's work}\newline
    \href{https://reader.elsevier.com/reader/sd/pii/S0021999117304588?token=27B5FCDE852ABD4BCA5D820B055D0B3DB365A6480F33F3B493D751636ED7B3022E5732B63C7EFBE609EC0C218FF980E7&originRegion=us-east-1&originCreation=20220928201508}{Reduced Order model via 2 point correlations (2017) Materials Science}\newline
    \href{https://reader.elsevier.com/reader/sd/pii/S1359645417310443?token=80B58C2FA5BF8E643CE2126B7EBF4EDA518A01E03E388665ADD5D11798BD7AFBACAC75E2DA798D3C67C66F9002B6314B&originRegion=us-east-1&originCreation=20220928201608}{Materials Science CNN}\newline
    \href{https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.2016.0446}{Learning PDEs via data discovery and sparse optimization}

\section{Original Work on SINDy}
\subsection{Some Context}
\begin{itemize}
    \item The goal is to extract parsimonious models from data. Can be called the dynamical system discovery problem.
    \item The framework is made possible by work from Bongard and Lipson (Automated reverse engineering of nonlinear dynamical systems), and Schmidt and Lipson (Distilling free-form natural laws from experimental data). The method uses \emph{symbolic regression} to find nonlienar differential equations, balancing complexity with accuracy.
    \item Symbolic regression is expensive, does not scale well to large systems, and can be prone to overfitting. 
    \item A good review of methods for the dynamical system discovery problem can be found here: \href{https://www.nature.com/articles/ncomms9133.pdf}{Automated adaptive inference of phenomenological dynamical models}.
\end{itemize}
\subsection{Sparse Identification of Nonlinear Dynamics (SINDy)}
Note, a useful appendix is found here: \href{https://www.pnas.org/action/downloadSupplement?doi=10.1073%2Fpnas.1517384113&file=pnas.1517384113.sapp.pdf}{Appendix}
\begin{itemize}
    \item Views dynamical system discovery from persepctive of sparse regression and compressed sensing.
    \item Assumes most physical systems have only a few relevant terms, making governing equations sparse in a high-dimensoonal nonlinear function space.
    \item Consider dynamical systems of the form
        \[
            \frac{d}{dt}\bm{x}(t) = f(\bm{x}(t))
        \]
    \item To determine the function $\bm{f}$ from data, we collect a time history of the state $\bm{x}(t)$ and either measure the derivative $\dot{\bm{x}}(t)$ or approximate it numerically from $\bm{x}(t)$. The data are sampled at $t_1, t_2, \dots, t_m$ and arranged into two matrices:
        \[
            \bm{X} = \begin{bmatrix}\bm{x}^T(t_1)\\ \bm{x}^T(t_2)\\ \vdots \\ \bm{x}^T(t_m)\end{bmatrix} = \begin{bmatrix}x_1(t_1) & x_2(t_1) & \dots & x_n(t_1)\\ x_1(t_2) & x_2(t_2) & \dots & x_n(t_2)\\ \vdots & \vdots & \ddots & \vdots \\ x_1(t_m) & x_2(t_m) & \dots & x_n(t_m)\end{bmatrix},
        \] 
        and
         \[
             \bm{\dot{X}} = \begin{bmatrix}\bm{\dot{x}}^T(t_1)\\ \bm{\dot{x}}^T(t_2)\\ \vdots \\ \bm{\dot{x}}^T(t_m)\end{bmatrix} = \begin{bmatrix}\dot{x}_1(t_1) & \dot{x}_2(t_1) & \dots & \dot{x}_n(t_1)\\ \dot{x}_1(t_2) & \dot{x}_2(t_2) & \dots & \dot{x}_n(t_2)\\ \vdots & \vdots & \ddots & \vdots \\ \dot{x}_1(t_m) & \dot{x}_2(t_m) & \dots & \dot{x}_n(t_m)\end{bmatrix}.
        \]
    \item Then we construct a library $\Theta(\bm{X})$ consisting of candidate nonlinear functions of the columns of $\bm{X}$. For example, $\Theta(\bm{X})$ may consist of constant, polynomical, and trigonometric terms:
        \[
            \Theta(\bm{X}) = \left[ \bm{1} \bm{X} \bm{X^{P_2}} \bm{X^{P_3}} \dots \sin(\bm{X}) \cos(\bm{X}) \dots \right].
        \]
    \item Each column of $\Theta(\bm{X})$ represents a candidate functions for the right-hand side.
    \item There is tremendous freedom in choosing the entries in this matrix of nonlinearities. Since we assume only a few of them are active in each row of $f$, we set up a sparse regression problem to determine the sparse vectors of coefficients
        \[
            \bm{\Xi} = \left[ \bm{\xi}_1 \bm{\xi}_2 ... \bm{\xi}_n\right]
        \] 
        that determine which nonlinearities are active:
        \[
            \dot{\bm{X}} = \Theta(\bm{X})\bm{\Xi}.
        \] 
       \end{itemize}
\section{SINDy + Coordinate Discovery - Includes PDE Example}
The main paper is \href{https://www.pnas.org/doi/pdf/10.1073/pnas.1906995116}{Data driven discovery of coordinates and governing equations}\newline
The code for this paper is here: \href{https://github.com/kpchamp/SindyAutoencoders}{github}
Also, there is a "supporting work" pdf available as well.\newline
This work breaks down the "data discovery process" in a few steps:
\begin{itemize}
    \item Measure data
    \item Approximate derivatives from data. If data is noisy, there is a method to handle that
    \item Construct library of functions.
    \item Jointly solve a sparse regression problem for model discovery, and use an autoeconder neural network for coordiante discover.
    \item I don't what this means yet, but will figure it out...
\end{itemize}

\subsection{10/4 - replicating results for Reaction-Diffusion equation}
\begin{itemize}
    \item I am going to try replicating result for the PDE presented.
    \item Step 1 is making or obtaining numerical solver for the PDE.
\end{itemize}
\subsubsection{Reaction Diffusion Data Acquisition/Simulation}
We wish to get data from the PDE
\begin{align*}
    u_t &= \left(1-(u^2+v^2) \right)u + \beta(u^2+v^2)v + d_1(u_{xx}+u_{yy})\\
    v_t &= -\beta(u^2+v^2)u + \left(1-(u^2+v^2)\right)v + d_2(v_{xx}+v_{yy}),
\end{align*}
with $d_1,d_2=.1$ and $\beta = 1$.
We will test the method on snapshots of the surface $u(x,y,t)$.
We will use a single initial condition,
\begin{align*}
    u(y_1,y_2,0)&= \tanh\left(\sqrt{y_1^2+y_2^2}\cos\left(\text{arg}(y_1+iy_2)-\sqrt{y_1^2+y_2^2}\right)\right)\\
    v(y_1,y_2,0) &= \tanh\left(\sqrt{y_1^2+y_2^2}\sin\left(\text{arg}(y_1+iy_2)-\sqrt{y_1^2+y_2^2}\right)\right).
\end{align*}
We use $t=0$ to $t=500$ with a spacing of $\Delta t = .05$

\end{document}

